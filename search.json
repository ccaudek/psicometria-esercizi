[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science con Python e R",
    "section": "",
    "text": "Benvenuti\nQuesto sito √® stato creato per supportare gli studenti del Corso di Laurea in Scienze e Tecniche Psicologiche dell‚ÄôUniversit√† degli Studi di Firenze nel consolidamento dei concetti appresi nell‚Äôinsegnamento di Psicometria (A.A. 2024/2025).\nIn questo sito √® presente una raccolta completa di esercizi, corredati dalle rispettive soluzioni, che spaziano dall‚Äôanalisi descrittiva ai modelli statistici pi√π complessi, coprendo l‚Äôintera gamma di argomenti trattati durante le lezioni. Le dispense di riferimento sono accessibili mediante il seguente link.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#informazioni-sullinsegnamento",
    "href": "index.html#informazioni-sullinsegnamento",
    "title": "Data Science con Python e R",
    "section": "Informazioni sull‚Äôinsegnamento",
    "text": "Informazioni sull‚Äôinsegnamento\n\n\nCodice: B000286 - PSICOMETRIA \n\nModulo: B000286 - PSICOMETRIA (Cognomi L-Z) \n\nCorso di laurea: Scienze e Tecniche Psicologiche \n\nAnno Accademico: 2024-2025 \n\nCalendario: Il corso si terr√† dal 3 marzo al 31 maggio 2025.\n\nOrario delle lezioni: Le lezioni si svolgeranno il luned√¨ e il marted√¨ dalle 8:30 alle 10:30 e il gioved√¨ dalle 11:30 alle 13:30.\n\nLuogo: Le lezioni si terranno presso il Plesso didattico La Torretta.\n\nModalit√† di svolgimento della didattica: Le lezioni ed esercitazioni saranno svolte in modalit√† frontale.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Questo repository fornisce esercizi pratici e soluzioni dettagliate per consolidare i concetti appresi nell‚Äôinsegnamento di Psicometria. Attraverso esempi concreti, esploreremo metodi di analisi dati pi√π robusti e replicabili, superando i limiti dell‚Äôapproccio frequentista.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "chapters/python/01_python.html",
    "href": "chapters/python/01_python.html",
    "title": "1¬† Python: Data Structures",
    "section": "",
    "text": "Esercizio 1.1 Write a function that takes a list of numbers and returns a new list containing: 1. All even numbers from the original list 2. Sorted in descending order 3. With duplicates removed\nExample input: [1, 4, 2, 7, 8, 2, 3, 4, 9, 6]\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Here‚Äôs the solution with explanation:\n\ndef process_numbers(numbers):\n    # Convert to set to remove duplicates\n    # Filter for even numbers\n    # Sort in descending order\n    result = sorted(\n        {num for num in numbers if num % 2 == 0},\n        reverse=True\n    )\n    return result\n\n# Test the function\ntest_list = [1, 4, 2, 7, 8, 2, 3, 4, 9, 6]\nprint(f\"Original list: {test_list}\")\nprint(f\"Processed list: {process_numbers(test_list)}\")\n\nOriginal list: [1, 4, 2, 7, 8, 2, 3, 4, 9, 6]\nProcessed list: [8, 6, 4, 2]\n\n\nExplanation: - We use a set comprehension to simultaneously remove duplicates and filter even numbers - The sorted() function with reverse=True handles the descending order requirement - This solution has O(n log n) time complexity due to the sorting operation\n\n\nEsercizio 1.2 Create a function that takes a string of words and returns a dictionary where: - Keys are the words - Values are dictionaries containing: - ‚Äòlength‚Äô: length of the word - ‚Äòvowels‚Äô: count of vowels in the word - ‚Äòpalindrome‚Äô: boolean indicating if the word is a palindrome\nExample input: ‚Äúlevel python noon code‚Äù\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Here‚Äôs the solution with explanation:\n\ndef analyze_words(text):\n    def count_vowels(word):\n        return sum(1 for char in word.lower() if char in 'aeiou')\n    \n    def is_palindrome(word):\n        word = word.lower()\n        return word == word[::-1]\n    \n    words = text.split()\n    result = {}\n    \n    for word in words:\n        result[word] = {\n            'length': len(word),\n            'vowels': count_vowels(word),\n            'palindrome': is_palindrome(word)\n        }\n    \n    return result\n\n# Test the function\ntext = \"level python noon code\"\nanalysis = analyze_words(text)\nfor word, info in analysis.items():\n    print(f\"\\n{word}:\")\n    for key, value in info.items():\n        print(f\"  {key}: {value}\")\n\n\nlevel:\n  length: 5\n  vowels: 2\n  palindrome: True\n\npython:\n  length: 6\n  vowels: 1\n  palindrome: False\n\nnoon:\n  length: 4\n  vowels: 2\n  palindrome: True\n\ncode:\n  length: 4\n  vowels: 2\n  palindrome: False\n\n\nExplanation: - We define helper functions for vowel counting and palindrome checking - The main function creates a dictionary comprehension with nested dictionaries - Each word is analyzed only once, making it efficient for large inputs",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Python: Data Structures</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_eda.html",
    "href": "chapters/eda/01_eda.html",
    "title": "2¬† Causalit√†",
    "section": "",
    "text": "Esercizio 2.1 Consideriamo il seguente DAG dove A influenza B e D, B influenza C, e D influenza B.\n\n\n\n\n\n\n\n\n\nSe vogliamo stimare l‚Äôeffetto causale di A su C, quale delle seguenti affermazioni √® corretta riguardo alla d-separazione e al controllo delle variabili?\n\nControllare per B √® sufficiente e necessario per ottenere una stima non distorta dell‚Äôeffetto di A su C.\nControllare per D √® necessario per bloccare il back-door path tra A e C.\nNon √® necessario controllare per alcuna variabile, poich√© non ci sono confondenti tra A e C.\nControllare sia per B che per D √® necessario per ottenere una stima non distorta dell‚Äôeffetto di A su C.\nControllare per B potrebbe introdurre un bias, poich√© B √® un collider nel percorso A ‚Üí B ‚Üê D.\n\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Risposta corretta:\n\nControllare per B √® sufficiente e necessario per ottenere una stima non distorta dell‚Äôeffetto di A su C.\n\nSpiegazione: In questo DAG, B agisce come un mediatore nella catena causale da A a C (A ‚Üí B ‚Üí C). Controllare per B √® sufficiente per bloccare il flusso di informazioni lungo questo percorso. Inoltre, B √® anche un collider nel percorso A ‚Üí B ‚Üê D, ma questo percorso non crea un back-door path tra A e C, quindi non √® necessario controllare per D. Controllare per B √® necessario perch√© altrimenti l‚Äôeffetto di A su C attraverso B non verrebbe rimosso. Le altre opzioni sono errate perch√©:\n\nNon c‚Äô√® un back-door path da A a C attraverso D.\nB √® un mediatore che deve essere controllato.\nControllare per D non √® necessario e potrebbe introdurre bias.\nB non √® un collider nel percorso rilevante per l‚Äôeffetto di A su C.\n\n\n\nEsercizio 2.2 Consideriamo il seguente DAG dove X √® la variabile di esposizione, Y √® l‚Äôoutcome, e Z e W sono altre variabili nel sistema.\n\n\n\n\n\n\n\n\n\nSe vogliamo stimare l‚Äôeffetto causale di X su Y utilizzando il criterio del back-door, quale delle seguenti affermazioni √® corretta?\n\nNon √® necessario controllare per alcuna variabile, poich√© non ci sono back-door paths tra X e Y.\n√à necessario controllare solo per Z per bloccare tutti i back-door paths tra X e Y.\n√à necessario controllare solo per W per bloccare tutti i back-door paths tra X e Y.\n√à necessario controllare sia per Z che per W per bloccare tutti i back-door paths tra X e Y.\nNon √® possibile stimare l‚Äôeffetto causale di X su Y in questo DAG utilizzando il criterio del back-door.\n\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Risposta corretta:\n\n√à necessario controllare solo per Z per bloccare tutti i back-door paths tra X e Y.\n\nSpiegazione: In questo DAG, esiste un back-door path tra X e Y attraverso Z (X ‚Üê Z ‚Üí W ‚Üí Y). Secondo il criterio del back-door, per ottenere una stima non distorta dell‚Äôeffetto causale di X su Y, dobbiamo bloccare tutti i back-door paths tra queste variabili.\nControllare per Z √® sufficiente per bloccare questo back-door path, poich√© Z √® una ‚Äúforchetta‚Äù (fork) nel percorso. Una volta che controlliamo per Z, il flusso di informazioni non causali da X a Y attraverso questo percorso viene bloccato.\nLe altre opzioni sono errate perch√©:\n\nC‚Äô√® un back-door path che deve essere bloccato.\nControllare solo per W non √® sufficiente, poich√© non blocca il flusso di informazioni attraverso Z.\nNon √® necessario controllare per W una volta che si √® controllato per Z. Controllare per variabili non necessarie pu√≤ ridurre la precisione della stima.\n√à possibile stimare l‚Äôeffetto causale in questo DAG utilizzando il criterio del back-door, controllando per Z.\n\nQuesto esercizio illustra l‚Äôimportanza di identificare correttamente i back-door paths e di selezionare il set minimo di variabili necessarie per bloccarli quando si applica il criterio del back-door nell‚Äôinferenza causale.\n\n\nEsercizio 2.3 Consideriamo il seguente DAG dove A e B influenzano C indipendentemente, e C influenza D.\n\n\n\n\n\n\n\n\n\nSupponiamo di voler studiare la relazione tra A e B. Quale delle seguenti affermazioni √® corretta riguardo a questo DAG e al concetto di collider?\n\nA e B sono indipendenti, ma diventano dipendenti se controlliamo per C.\nA e B sono dipendenti, ma diventano indipendenti se controlliamo per C.\nA e B sono sempre dipendenti, indipendentemente dal fatto che controlliamo o meno per C.\nA e B sono sempre indipendenti, indipendentemente dal fatto che controlliamo o meno per C o D.\nControllare per D √® necessario per rendere A e B indipendenti.\n\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Risposta corretta:\n\nA e B sono indipendenti, ma diventano dipendenti se controlliamo per C.\n\nSpiegazione: In questo DAG, C √® un collider rispetto ad A e B. Un collider √® una variabile che riceve frecce da due o pi√π altre variabili nel grafo. Il comportamento dei collider √® particolare e contro-intuitivo nell‚Äôanalisi causale.\nQuando non controlliamo per un collider o per i suoi discendenti:\n\nLe variabili che influenzano il collider (in questo caso, A e B) sono indipendenti tra loro.\n\nQuando controlliamo per un collider o per i suoi discendenti:\n\nIntroduciamo una dipendenza tra le variabili che influenzano il collider.\n\nQuindi, in questo caso:\n\nA e B sono originariamente indipendenti.\nSe controlliamo per C (il collider), creiamo una dipendenza tra A e B.\nAnche controllare per D (discendente del collider) creerebbe una dipendenza tra A e B.\n\nLe altre opzioni sono errate perch√©:\n\nLa direzione della dipendenza √® opposta a quella corretta.\nA e B non sono sempre dipendenti; lo diventano solo se controlliamo per C o D.\nA e B diventano dipendenti se controlliamo per C o D.\nControllare per D non rende A e B indipendenti, ma al contrario crea una dipendenza.\n\nQuesto esercizio illustra l‚Äôimportanza di identificare correttamente i collider in un DAG e di comprendere come il controllo di queste variabili possa influenzare le relazioni tra altre variabili nel sistema.\n\n\nEsercizio 2.4 Consideriamo il seguente DAG dove X √® la variabile di esposizione, Y √® l‚Äôoutcome, U √® una variabile non osservata, e Z √® una variabile osservata.\n\n\n\n\n\n\n\n\n\nQuale delle seguenti affermazioni √® corretta riguardo all‚Äôapplicazione del criterio del back-door per stimare l‚Äôeffetto causale di X su Y in questo DAG?\n\nNon √® possibile applicare il criterio del back-door perch√© U non √® osservata.\nControllare per Z √® sufficiente per bloccare tutti i back-door paths tra X e Y.\nControllare per Z non √® necessario perch√© non ci sono back-door paths tra X e Y.\n√à necessario controllare sia per U che per Z per ottenere una stima non distorta dell‚Äôeffetto causale di X su Y.\nControllare per Z potrebbe introdurre un bias nella stima dell‚Äôeffetto causale di X su Y.\n\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Risposta corretta:\n\nControllare per Z potrebbe introdurre un bias nella stima dell‚Äôeffetto causale di X su Y.\n\nSpiegazione: In questo DAG, abbiamo la seguente situazione:\n\nC‚Äô√® un back-door path da X a Y attraverso U (X ‚Üê U ‚Üí Y). Questo percorso crea confondimento.\nZ √® un collider nel percorso X ‚Üí Z ‚Üê Y.\nU non √® osservata, quindi non possiamo controllare direttamente per essa.\n\nApplicando il criterio del back-door:\n\nNon possiamo bloccare il back-door path X ‚Üê U ‚Üí Y perch√© U non √® osservata.\nControllare per Z non aiuterebbe a bloccare questo back-door path.\nAnzi, controllare per Z (un collider) aprirebbe un nuovo percorso non causale tra X e Y, introducendo un bias nella stima dell‚Äôeffetto causale.\n\nLe altre opzioni sono errate perch√©:\n\nAnche se U non √® osservata, possiamo ancora applicare il criterio del back-door per analizzare la situazione.\nControllare per Z non √® sufficiente e anzi introdurrebbe un bias.\nC‚Äô√® un back-door path attraverso U.\nNon possiamo controllare per U poich√© non √® osservata.\n\nQuesto esercizio illustra l‚Äôimportanza di identificare correttamente i back-door paths e i collider in un DAG, e di comprendere come la presenza di variabili non osservate possa complicare l‚Äôapplicazione del criterio del back-door nell‚Äôinferenza causale.\n\n\nEsercizio 2.5 Considera le relazioni tra le variabili:\n\n\\(A \\sim \\mathcal{N}(0, 1)\\).\n\\(M = A + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\),\n\\(B = M + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\).\n\n\nIdentifica la struttura causale risultante.\nCrea una simulazione in Python con le precedenti relazioni tra variabili (con \\(n\\) = 10,000) e crea un diagramma a dispersione per A e B.\nCalcola la correlazione tra A e B.\n\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. La struttura causale √® quella della mediazione.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# A √® una variabile casuale distribuita secondo una normale standard\nA = np.random.normal(0, 1, n)\n\n# M √® una funzione lineare di A con un termine di errore\nM = A + np.random.normal(0, 1, n)\n\n# B √® una funzione lineare di M con un termine di errore\nB = M + np.random.normal(0, 1, n)\n\n# Plot di A contro B\nplt.scatter(A, B, alpha=0.5)\nplt.xlabel('A')\nplt.ylabel('B')\nplt.title('Relazione tra A e B')\nplt.show()\n\n# Calcolo della correlazione tra A e B\ncorrelation_matrix = np.corrcoef(A, B)\ncorrelation = correlation_matrix[0, 1]\n\n# Stampa il valore della correlazione\nprint(f\"Correlazione tra A e B: {correlation:.4f}\")\n\n\n\n\n\n\n\n\nCorrelazione tra A e B: 0.5807\n\n\n\n\nEsercizio 2.6 Considera le seguenti relazioni tra le variabili:\n\n\\(C \\sim \\mathcal{N}(0, 1)\\),\n\\(A = C + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\),\n\\(B = C + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\).\n\n\nIdentifica la struttura causale risultante.\nCrea una simulazione in Python con le precedenti relazioni tra variabili (con \\(n\\) = 10,000) e crea un diagramma a dispersione per A e B.\nCalcola la correlazione tra A e B.\n\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Se \\(A\\) e \\(B\\) condividono un antenato comune \\(C\\) (biforcazione causale), \\(A\\) e \\(B\\) saranno correlati nei dati. Questo fenomeno √® chiamato confondimento. La regola si applica anche se l‚Äôeffetto di C su A e/o su B √® mediato da altre variabili.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# C √® una variabile casuale distribuita secondo una normale standard\nC = np.random.normal(0, 1, n)\n\n# A √® una funzione lineare di C con un termine di errore\nA = C + np.random.normal(0, 1, n)\n\n# B √® una funzione lineare di C con un termine di errore\nB = C + np.random.normal(0, 1, n)\n\n# Plot di A contro B\nplt.scatter(A, B, alpha=0.5)\nplt.xlabel('A')\nplt.ylabel('B')\nplt.title('Relazione tra A e B')\nplt.show()\n\n# Calcolo della correlazione tra A e B\ncorrelation_matrix = np.corrcoef(A, B)\ncorrelation = correlation_matrix[0, 1]\n\n# Stampa il valore della correlazione\nprint(f\"Correlazione tra A e B: {correlation:.4f}\")\n\n\n\n\n\n\n\n\nCorrelazione tra A e B: 0.4958\n\n\n\n\nEsercizio 2.7 Consideriamo la struttura causale del confondimento, in cui una variabile \\(C\\) influenza entrambe le variabili \\(A\\) e \\(B\\):\n\n\\(C \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(C\\) √® distribuita secondo una normale standard),\n\\(A = C + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(A\\) √® una funzione di \\(C\\) con un termine di errore additivo),\n\\(B = C + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(B\\) √® una funzione di \\(C\\) con un altro termine di errore additivo).\n\nIn questa simulazione Python, si genericno 10,000 osservazioni secondo le relazioni sopra descritte. Successivamente, si calcolino i residui della regressione di \\(A\\) su \\(C\\) e di \\(B\\) su \\(C\\). Questi residui rappresentano le componenti di \\(A\\) e \\(B\\) indipendenti linearmente da \\(C\\). Infine, calcoli la correlazione tra i residui di \\(A\\) e \\(B\\), ovvero la correlazione tra \\(A\\) e \\(B\\) dopo aver controllato l‚Äôeffetto di \\(C\\). Si interpretino i risultati.\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. \n\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# Generazione delle variabili secondo le specifiche\nC = np.random.normal(0, 1, n)\nA = C + np.random.normal(0, 1, n)\nB = C + np.random.normal(0, 1, n)\n\n# Regressione A ~ C per ottenere i residui\nmodel_A_C = sm.OLS(A, sm.add_constant(C)).fit()\nresiduals_A = model_A_C.resid\n\n# Regressione B ~ C per ottenere i residui\nmodel_B_C = sm.OLS(B, sm.add_constant(C)).fit()\nresiduals_B = model_B_C.resid\n\n# Calcolo della correlazione tra i residui di A e B\ncorrelation_residuals = np.corrcoef(residuals_A, residuals_B)[0, 1]\n\n# Stampa del risultato\nprint(f\"Correlazione tra A e B dopo aver controllato per C: {correlation_residuals:.4f}\")\n\n# Plot dei residui di A contro i residui di B\nplt.scatter(residuals_A, residuals_B, alpha=0.5)\nplt.xlabel('Residui di A')\nplt.ylabel('Residui di B')\nplt.title('Correlazione tra i residui di A e B')\nplt.show()\n\nCorrelazione tra A e B dopo aver controllato per C: 0.0060\n\n\n\n\n\n\n\n\n\n\n\nEsercizio 2.8 Consideriamo la struttura causale della mediazione, in cui una variabile \\(A\\) influenza una variabile \\(M\\), che a sua volta influenza una variabile \\(B\\):\n\n\\(A \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(A\\) √® distribuita secondo una normale standard),\n\\(M = A + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(M\\) √® una funzione di \\(A\\) con un termine di errore additivo),\n\\(B = M + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(B\\) √® una funzione di \\(M\\) con un altro termine di errore additivo).\n\nIn questa simulazione Python, genera 10.000 osservazioni secondo le relazioni sopra descritte. Successivamente, calcola i residui della regressione di \\(M\\) su \\(A\\) e di \\(B\\) su \\(M\\). Questi residui rappresentano le componenti di \\(M\\) e \\(B\\) indipendenti linearmente da \\(A\\) e \\(M\\), rispettivamente. Infine, calcoleremo la correlazione tra \\(A\\) e i residui di \\(B\\), ovvero la correlazione tra \\(A\\) e \\(B\\) dopo aver controllato per l‚Äôeffetto della mediazione attraverso \\(M\\).\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. \n\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# Generazione delle variabili secondo le specifiche\nA = np.random.normal(0, 1, n)\nM = A + np.random.normal(0, 1, n)\nB = M + np.random.normal(0, 1, n)\n\n# Regressione M ~ A per ottenere i residui\nmodel_M_A = sm.OLS(M, sm.add_constant(A)).fit()\nresiduals_M = model_M_A.resid\n\n# Regressione B ~ M per ottenere i residui\nmodel_B_M = sm.OLS(B, sm.add_constant(M)).fit()\nresiduals_B = model_B_M.resid\n\n# Calcolo della correlazione tra A e i residui di B\ncorrelation_residuals = np.corrcoef(A, residuals_B)[0, 1]\n\n# Stampa del risultato\nprint(f\"Correlazione tra A e i residui di B (dopo aver controllato per M): {correlation_residuals:.4f}\")\n\n# Plot di A contro i residui di B\nplt.scatter(A, residuals_B, alpha=0.5)\nplt.xlabel('A')\nplt.ylabel('Residui di B')\nplt.title('Correlazione tra A e i residui di B')\nplt.show()\n\nCorrelazione tra A e i residui di B (dopo aver controllato per M): -0.0006\n\n\n\n\n\n\n\n\n\nSe \\(M\\) media completamente l‚Äôeffetto di \\(A\\) su \\(B\\), ci aspettiamo che, una volta controllato \\(M\\), non ci sia alcuna correlazione residua significativa tra \\(A\\) e \\(B\\). La correlazione calcolata dovrebbe essere prossima a zero se la mediazione √® completa. Se la correlazione √® significativamente diversa da zero, potrebbe indicare che esistono effetti diretti di \\(A\\) su \\(B\\) non mediati da \\(M\\) o che esistono altri percorsi attraverso i quali \\(A\\) influenza \\(B\\).\n\n\nEsercizio 2.9 Consideriamo ora la struttura causale di un collider, in cui due variabili indipendenti \\(A\\) e \\(B\\) influenzano entrambe una variabile \\(M\\). In questa configurazione, \\(M\\) √® il collider. Un aspetto fondamentale di questa struttura √® che il controllo su \\(M\\) (il collider) pu√≤ indurre una correlazione spuria tra \\(A\\) e \\(B\\), anche se \\(A\\) e \\(B\\) non sono direttamente correlati.\nLe relazioni causali sono le seguenti:\n\n\\(A \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(A\\) √® distribuita secondo una normale standard),\n\\(B \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(B\\) √® distribuita secondo una normale standard),\n\\(C = A + B + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(C\\) √® una funzione di \\(A\\) e \\(B\\) con un termine di errore additivo).\n\nIn questa simulazione Python, genera 10,000 osservazioni secondo le relazioni sopra descritte. Successivamente, calcola i residui della regressione di \\(C\\) su \\(A\\) e \\(B\\). Infine, calcola la correlazione tra \\(A\\) e \\(B\\) dopo aver controllato per \\(C\\).\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. \n\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# Generazione delle variabili secondo le specifiche\nA = np.random.normal(0, 1, n)\nB = np.random.normal(0, 1, n)\nD = A + B + np.random.normal(0, 1, n)\n\n# Regressione A ~ D per ottenere i residui\nmodel_A_D = sm.OLS(A, sm.add_constant(D)).fit()\nresiduals_A = model_A_D.resid\n\n# Regressione B ~ D per ottenere i residui\nmodel_B_D = sm.OLS(B, sm.add_constant(D)).fit()\nresiduals_B = model_B_D.resid\n\n# Plot dei residui di A contro i residui di B\nplt.scatter(residuals_A, residuals_B, alpha=0.5)\nplt.xlabel(\"Residui di A\")\nplt.ylabel(\"Residui di B\")\nplt.title(\"Correlazione tra i residui di A e B dopo aver controllato per D\")\nplt.show()\n\n# Calcolo della correlazione tra A e i residui di B\ncorrelation_residuals = np.corrcoef(residuals_A, residuals_B)[0, 1]\n\n# Stampa del risultato\nprint(\n    f\"Correlazione tra A e i residui di B (dopo aver controllato per D): {correlation_residuals:.4f}\"\n)\n\n\n\n\n\n\n\n\nCorrelazione tra A e i residui di B (dopo aver controllato per D): -0.5032\n\n\nIn una struttura causale di tipo collider, A e B sono indipendenti, ma quando si controlla per D si pu√≤ generare una correlazione spuria tra A e B. Questo effetto √® dovuto alla struttura del collider: controllare per D introduce una dipendenza tra A e B, anche se non esiste un legame diretto tra loro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Causalit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_probability.html",
    "href": "chapters/probability/01_probability.html",
    "title": "3¬† Probabilit√†",
    "section": "",
    "text": "Esercizio 3.1 Supponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual √® la probabilit√† che almeno 2 psicologi clinici siano nella commissione? Risolvi il problema usando una simulazione Monte Carlo.\n\n\nüëÄ Visualizza la Soluzione\n\n\nSoluzione. Per calcolare questa probabilit√† in maniera analitica, utilizziamo la seguente uguaglianza:\n\\[\nP(\\text{almeno 2 psicologi clinici}) = 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}).\n\\]\nIl numero totale di modi per selezionare 5 persone dal gruppo di 20 √® dato da:\n\\[\n\\binom{20}{5} = \\frac{20!}{5!(15!)} = 15,504.\n\\]\nIl numero di modi per avere nessun psicologo clinico nella commissione (ovvero, selezionare solo psicologi del lavoro) √®:\n\\[\n\\binom{10}{0} \\times \\binom{10}{5} = 1 \\times 252 = 252.\n\\]\nQuindi, la probabilit√† di avere nessun psicologo clinico √®:\n\\[\nP(\\text{nessun psicologo clinico}) = \\frac{252}{15,504} \\approx 0.016.\n\\]\nIl numero di modi per avere esattamente 1 psicologo clinico nella commissione √®:\n\\[\n\\binom{10}{1} \\times \\binom{10}{4} = 10 \\times 210 = 2,100.\n\\]\nQuindi, la probabilit√† di avere esattamente 1 psicologo clinico √®:\n\\[\nP(\\text{1 psicologo clinico}) = \\frac{2,100}{15,504} \\approx 0.135.\n\\]\nLa probabilit√† di avere almeno 2 psicologi clinici nella commissione √® quindi:\n\\[\n\\begin{align}\nP(\\text{almeno 2 psicologi clinici}) &= 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}) \\notag\\\\\n&= 1 - 0.016 - 0.135 \\notag\\\\\n&= 0.848.\\notag\n\\end{align}\n\\]\nQuindi, la probabilit√† che almeno 2 psicologi clinici siano nella commissione √® circa 0.848.\n\nimport numpy as np\nimport scipy.stats as stats\nimport math\n\n\n# Funzione per calcolare le combinazioni\ndef nCk(n, k):\n    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n\n\n# Calcolo delle probabilit√† per il problema della commissione\ntotal_ways = nCk(20, 5)\nno_clinical = nCk(10, 0) * nCk(10, 5)\none_clinical = nCk(10, 1) * nCk(10, 4)\n\np_no_clinical = no_clinical / total_ways\np_one_clinical = one_clinical / total_ways\n\np_at_least_two_clinical = 1 - p_no_clinical - p_one_clinical\n\nprint(f\"Probabilit√† di almeno 2 psicologi clinici: {p_at_least_two_clinical:.3f}\")\n\nProbabilit√† di almeno 2 psicologi clinici: 0.848\n\n\nIn maniera pi√π intuitiva, possiamo risolvere il problema con una simulazione Monte Carlo.\n\nimport random\n\n# Numero di simulazioni\nsimulations = 1000000\n\n# Numero di successi (almeno 2 psicologi clinici nella commissione)\nsuccess_count = 0\n\n# Creiamo una lista che rappresenta il gruppo di 20 persone\n# 1 rappresenta un psicologo clinico, 0 rappresenta un psicologo del lavoro\ngroup = [1] * 10 + [0] * 10\n\n# Simulazione Monte Carlo\nfor _ in range(simulations):\n    # Estrai casualmente 5 persone dal gruppo\n    committee = random.sample(group, 5)\n\n    # Conta quanti psicologi clinici ci sono nella commissione\n    num_clinical_psychologists = sum(committee)\n\n    # Verifica se ci sono almeno 2 psicologi clinici\n    if num_clinical_psychologists &gt;= 2:\n        success_count += 1\n\n# Calcola la probabilit√†\nprobability = success_count / simulations\n\n# Mostra il risultato\nprint(\n    f\"La probabilit√† che almeno 2 psicologi clinici siano nella commissione √®: {probability:.4f}\"\n)\n\nLa probabilit√† che almeno 2 psicologi clinici siano nella commissione √®: 0.8472",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Probabilit√†</span>"
    ]
  }
]